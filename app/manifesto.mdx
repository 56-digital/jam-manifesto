import { DrumMachine } from '@/components/DrumMachine'
import { MermaidDiagram } from '@/components/MermaidDiagram'

<div className="manifesto">

<p className="eyebrow" style={{color:'#4a5d6d',fontSize:'11px',letterSpacing:'0.2em',textTransform:'uppercase',marginBottom:'12px'}}>working document — rev 0.1</p>

# Jam Manifesto

---

## I.

There is a ritual to patching a modular synthesizer.

<img src="/modular-setup.jpg" alt="Two modular synthesizer cases on a table, covered in patch cables" />

You take the cable in your hand, find the output you want, trace the signal path in your mind before your hands move — then patch in sequence, listening carefully as each new connection changes what you hear. Routing an envelope follower to a filter is not one action but a series of small decisions, each one requiring you to look at the panel, identify the correct jack, choose the right depth on the attenuator, verify that the signal is going where you want it to go. The slowness is not incidental to the process. The slowness is the process. The deliberate physical motion of the cable from one point to another is part of how the music gets made.

I know that ritual. I love that ritual. There is something irreplaceable about the physicality of it, about the way working with constraints forces a kind of intimacy with the system.

And then I said, out loud, into a session that was running " *add a filter, open it with an envelope.*"

And it opened. As I was finishing the sentence, the filter traversed. There were no cables, there were no menus. There was just the distance between the thought and the sound, and it had collapsed to the length of a sentence.

That moment felt genuinely surreal. Not like cheating, and not like a shortcut but like finally being understood by something that had been listening the whole time.

---

## II.

The distance between what you can hear in your mind and what you can actually make has always been the central problem of creative technology [NOTE: is this too big of a stance and should be positioned more personally? of my creative practice?]. Every instrument ever built is a partial solution to it. Every interface, every notation system, every piece of software is an attempt to close that gap a little further.

Karlheinz Stockhausen described what felt like a breakthrough when he began working in the electronic music studios in Cologne in the early 1950s, the discovery that you could *draw* a sound. That rather than writing symbols on a staff and hoping a musician would interpret them correctly, you could draw the shape of an envelope directly, sketch hills and mountains on paper and watch them become the actual contour of the sound as it moved through time. The shape was the sound. Notation had always been an approximation; here the score and the result could be the same thing.

<img src="/stockhausen-drawing.jpg" alt="Stockhausen drawing envelopes on a whiteboard" style={{maxWidth:'680px',width:'100%',marginLeft:'auto',marginRight:'auto'}} />
<img src="/stockhausen-notation.jpg" alt="Stockhausen's hand-drawn frequency notation, 1000 c/s marked" style={{maxWidth:'680px',width:'100%',marginLeft:'auto',marginRight:'auto'}} />

Daphne Oram was working through similar questions. In *An Individual Note of Music, Sound and Electronics* she described what happens when you set a series of oscillators at different frequencies and let them interact: some cancel each other out, some reinforce, the mathematics of interference becoming audible in a way that is both precise and deeply strange to listen to. Reading her description, I heard it clearly — all of the oscillators, all of the relationships between them. Then I opened a blank patch and started clicking.

That is the distance.

Stockhausen compressed it by letting you draw. Oram spent a lifetime trying to compress it further, building a machine where drawn marks directly controlled the synthesis of sound. What has changed now is not the nature of the problem but the nature of the interface: you don't draw the hills. *You describe the Swiss Alps*, slow rise over several kilometers, a sharp sudden peak, then the long drop into the valley, and the system finds the shape.

---

## III.

The mental model is simple: you describe and the system builds.

Not in the way that current AI tools generate music — passive, opaque, something that happens to you rather than with you. This is a different relationship entirely. The building blocks are the same ones that have existed since the first synthesizer was wired together in a laboratory. Oscillators, filters, envelopes, buses, gates, control voltage. The same primitives that Stockhausen worked with at WDR, the same signal chain you would patch together by hand on a modular. Nothing here is invented and what changes is only the interface.

You say: *place twelve oscillators, stepped from 100 Hz to 1 kHz in increments of 100.* They appear — connected, routed to the bus, audible immediately. Then: *add a spectrogram so I can see the frequencies as they interact.* It appears. Then: *give each one its own amplitude control, I want to be able to bring each frequency in and out independently.* Twelve fader, with each one live and mapped to a running oscillator.

What would have taken twenty minutes of careful clicking now takes perhaps forty seconds of describing. And you never left the thought. You stayed in the space where the music was already playing in your mind, and the system caught up to you rather than the other way around.

The constraint becomes your creativity, not your tools.

<DrumMachine />

---

## IV.

Signals are numbers, moving between -1 and 1, and everything else — every sound you have ever heard or made or imagined — is just a question of what you do with them. A gate is nothing more than a signal that is either open or closed, a decision made thousands of times a second about whether something passes through or stops. An envelope describes the shape of how something changes over time — the sharp rise and slow fall of a struck piano string, or the gradual swell of something building toward a peak. A bus is a shared path that multiple signals can travel down together. A filter is a negotiation between which frequencies reach the listener and which disappear into the space behind them.

If you have ever turned down the low end on a speaker, or noticed how a sound grows softer as it moves away, or felt the way a piece of music builds toward something and then releases, then you already know the primitives. They're not technical knowledge, they're the physics of how sound works, translated into parameters you can reach.

You don't need to know the correct name for what you want. If you say *make it brighter*, the system knows you mean the filter. If you say *make it breathe*, it knows you are describing a volume envelope. If you say *something falling*, thrown from a height, losing speed as it goes — it finds the curve and attaches the mathematical shape that matches what you saw.

The description is the patch cable. The language is the instrument. 

---

## V.

I enjoy making music together with friends where each person brings their own system and you run everything to the same clock so the tempos lock and the machines begin to breathe together. There was a drum machine, and two synthesizer setups, and we would each be listening, adjusting, and responding to what the others were doing in a way that felt less like performing separately and more like a conversation that could only exist in this particular language. 

When something changed in one part of the setup, a texture shifting across the room, a sequence suddenly turning in a new direction, the rest of us heard it and moved accordingly. There was a call and response quality to it that didn't need to be spoken or planned in advance. It emerged from the middle of everything, from all of us paying close attention to the same living thing at the same time. The music was made in the space between... not by any one of us indiviudally. 

What made that quality of presence possible was not wireless — the feeling that each person's choices were immediately audible to everyone else, that there was almost no distance between a decision and its effect. Part of it were cables. Physical connections between physical machines, a patch cable running from one synthesizer output to another, voltage moving through copper wire from one case to the next. You could see where your system ended and someone else's began. You could trace the signal path across the table with your finger.

A LAN cable is not a patch cable in the literal sense. The signal it carries is abstracted several layers beyond analog voltage. It is packets, it is protocol, it is a set of conventions that make it possible for completely different machines to understand each other. But there is something about running a long ethernet cable across the floor and plugging it into a switch, about choosing the physical connection over the invisible convenience of WiFi, that restores a version of that feeling. In a world where most connectivity has become imperceptible, where devices talk to each other through the air without any visible evidence of the conversation, there is something almost visceral about a cable you can follow with your eyes from one point to another.

You can see where your machine enters the network. You can feel, in some non-literal way, the pulse of what is happening.

<MermaidDiagram chart={`graph TD
  HOST["host machine"]
  SW["ethernet switch"]
  EQ["EQ + amplifier"]
  SPK["speakers"]
  HOST --> SW
  HOST --> EQ
  EQ --> SPK
  SW --> P1["device 01"]
  SW --> P2["device 02"]
  SW --> P3["device 03"]
  SW --> P4["device 04"]
  SW --> P5["..."]
  SW --> P24["device 24"]`}
/>

<img src="/cables-server.jpg" alt="Server racks overflowing with red ethernet cables" style={{maxWidth:'680px',width:'100%',marginLeft:'auto',marginRight:'auto'}} />
<img src="/lan-party.jpg" alt="LAN party — laptops, cables, Coca-Cola cans, headphones" style={{maxWidth:'680px',width:'100%',marginLeft:'auto',marginRight:'auto'}} />
<img src="/modular-pyramid.jpg" alt="Modular synthesizer mounted on a steel pyramid sculpture" style={{maxWidth:'680px',width:'100%',marginLeft:'auto',marginRight:'auto'}} />
<img src="/server-stress.jpg" alt="Man standing in a server room with hands on his head" style={{maxWidth:'680px',width:'100%',marginLeft:'auto',marginRight:'auto'}} />

---

## VI.

The installation is built around the choice to make the network visible.

At the center of the room is a single machine: a server connected to an audio interface, connected to an equalizer, connected to speakers. Everything that will be heard in the room passes through this machine first. It is not a mixer in the traditional sense, it is more like the root of a nervous system, the point from which everything else branches.

From a switch connected to that machine, ethernet cables run out across the floor to wherever people have chosen to sit. 24 ports, which invite 24 possible participants, each one bringing a laptop and plugging in. From the moment the cable is connected, their device is part of the system. Their voice, their descriptions, their commands travel from their machine over the cable to the switch to the central engine, which interprets them, processes them, adds them to the sound that is already happening in the room.

The cables are intentionally long. They are part of the aesthetic. You are meant to see them crossing the floor, to understand at a glance the topology of what is happening: who is connected to what, where the center is, how far each person sits from it, the distance between. The server rack in the middle is not hidden away or disguised as furniture. It is a sculpture. It is the instrument.

<MermaidDiagram chart={`graph LR
  NL["natural language"] --> LLM["language model"]
  LLM --> OSC["OSC commands"]
  OSC --> SC["scsynth"]
  SC --> BUS["audio bus"]
  BUS --> OUT["speakers"]
  LLM --> SEQ["sequencer"]
  SEQ --> SC
  LINK["clock sync"] --> SEQ
  MCP["capability registry"] --> LLM`}
/>

---

## VII.

The workshop runs across three days, and the shape of those three days follows something like the arc of learning any instrument. Though it is not exactly that because the instrument here is not fixed, it's more like co-creating and co-playing. 

**Day one**<br />
The system is introduced and demonstrated where people arrive from different backgrounds. Some who make music regularly, some who never have, some who write code, some who don't. The first hour is about getting a feel for what the system is before anyone tries to use it: what it means for everything to be connected, what it sounds like when multiple people are working in the same session at the same time, what the relationship is between a description and a sound. Then the cables come out. IPs are assigned, each person's device is connected, we do a sound sound test. By the end of the day, something simple has been made collectively with a few sequences layered on top of each other, a shared clock, a room that is making noise together for the first time.

**Day two**<br />
People come back having slept on it. Some will have kept running the system overnight, experimenting on their own, building small things. There is a low-pressure session in the morning — everyone plugged in, no agenda — and then a brief showcase in the afternoon where people share what they found. *This worked well. The agent lost the thread here. I found a model that understood this kind of description better. I adjusted the prompt and the behavior changed.* The knowledge transfers laterally, person to person, in the way that knowledge about tools always does.

**Day three**<br />
It is a performance with all devices connected. The session runs for as long as the workshop with someone recording everything. People are playing and adjusting and responding to each other, building and dismantling and rebuilding in real time, and the room sounds like whatever it sounds like — which nobody will know until it happens.

</div>
